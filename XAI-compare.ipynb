{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Attribute exploration (ground truth labels for the images)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every image has annotations with ground truth values for the different attributes (312):\n",
    "\n",
    "* A 312 vector with values ranging from 0-1 -> I have binarized them for clarity\n",
    "*  Each of the values in the vector correspond to a defined attribute which I have also printed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute values: [0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1\n",
      " 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
      " 0 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 1 0\n",
      " 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0\n",
      " 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1\n",
      " 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0\n",
      " 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1]\n",
      "Top 5 attributes: ['150 has_bill_length::about_the_same_as_head', '146 has_eye_color::black', '245 has_belly_pattern::solid', '290 has_bill_color::black', '241 has_tail_pattern::solid']\n"
     ]
    }
   ],
   "source": [
    "# Load the attribute names from the attributes.txt file\n",
    "with open('/Users/lucialarraona/Desktop/responsibleai/ConceptBottleneck/CUB/CUB_200_2011/attributes.txt', 'r') as f:\n",
    "    attribute_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Load the class attribute labels from the class_attribute_labels_continuous.txt file\n",
    "class_attribute_labels = np.loadtxt('/Users/lucialarraona/Desktop/responsibleai/ConceptBottleneck/CUB/CUB_200_2011/CUB_200_2011/attributes/class_attribute_labels_continuous.txt')\n",
    "\n",
    "# Load the class labels for the images\n",
    "with open('/Users/lucialarraona/Desktop/responsibleai/ConceptBottleneck/CUB/CUB_200_2011/CUB_200_2011/image_class_labels.txt', 'r') as f:\n",
    "    class_labels = np.loadtxt(f, dtype=int, usecols=[1])\n",
    "\n",
    "# Get the attribute vector for the first image (index 0)\n",
    "image_index = 148\n",
    "attribute_vector = class_attribute_labels[class_labels[image_index] - 1]\n",
    "\n",
    "# Binarize the attribute vector\n",
    "binary_vector = (attribute_vector > 0.5).astype(int)\n",
    "\n",
    "# Get the top 5 attributes with the highest values\n",
    "top_indices = np.argsort(attribute_vector)[::-1][:5]\n",
    "top_attributes = [attribute_names[i] for i in top_indices]\n",
    "\n",
    "# Print the results\n",
    "print('Attribute values:', binary_vector)\n",
    "print('Top 5 attributes:', top_attributes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "* There is a mismatch because the image inside each folder has a capital letter instead of having the same name of the folder. Idk how to fix it.\n",
    "* I need to know the exact names of the images used in the saliency maps to extract the correct ground truth attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/lucialarraona/Desktop/responsibleai/ConceptBottleneck/CUB/CUB_200_2011/CUB_200_2011/images/000.001.Black_footed_Albatross/000.001.Black_footed_Albatross_0001.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m species_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(class_labels[image_index])\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m class_names[image_index]\n\u001b[1;32m      7\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/lucialarraona/Desktop/responsibleai/ConceptBottleneck/CUB/CUB_200_2011/CUB_200_2011/images/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(species_folder, species_folder, \u001b[38;5;28mstr\u001b[39m(image_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Display the image and print the results\u001b[39;00m\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py:2843\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2840\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   2842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 2843\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2844\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/lucialarraona/Desktop/responsibleai/ConceptBottleneck/CUB/CUB_200_2011/CUB_200_2011/images/000.001.Black_footed_Albatross/000.001.Black_footed_Albatross_0001.jpg'"
     ]
    }
   ],
   "source": [
    "# Load the image file names\n",
    "image_folder ='/Users/lucialarraona/Desktop/responsibleai/ConceptBottleneck/CUB/CUB_200_2011/CUB_200_2011/images/'\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "image_index = 0\n",
    "species_folder = str(class_labels[image_index]).zfill(3) + '.' + class_names[image_index]\n",
    "image_path = '/Users/lucialarraona/Desktop/responsibleai/ConceptBottleneck/CUB/CUB_200_2011/CUB_200_2011/images/{}/{}_{}.jpg'.format(species_folder, species_folder, str(image_index + 1).zfill(4))\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Display the image and print the results\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title('Image with ID {}'.format(image_index + 1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Validation strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of explanations provided by each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saliency map vs bounding boxes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the accuracy using the saliency map and the ground truth explanation (bounding box), we can use the following steps:\n",
    "\n",
    "To calculate the IoU, you can first convert the saliency map to a binary mask by thresholding it at a certain level (e.g., 0.5). Then, you can compute the intersection between the binary mask and the bounding box by multiplying them element-wise and summing the result. Similarly, you can compute the union between them by summing the number of pixels in both the binary mask and the bounding box and subtracting the intersection. Finally, you can calculate the IoU as the ratio of the intersection to the union.\n",
    "\n",
    "The higher the IoU value, the better the saliency map aligns with the ground truth bounding box. This measure provides a way to evaluate the quality of saliency maps and how well they capture the object of interest in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to saliency map\n",
    "PATH_saliency_map = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbox</th>\n",
       "      <th>index</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 60.0 27.0 325.0 304.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 139.0 30.0 153.0 264.0</td>\n",
       "      <td>2</td>\n",
       "      <td>139.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 14.0 112.0 388.0 186.0</td>\n",
       "      <td>3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 112.0 90.0 255.0 242.0</td>\n",
       "      <td>4</td>\n",
       "      <td>112.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 70.0 50.0 134.0 303.0</td>\n",
       "      <td>5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11783</th>\n",
       "      <td>11784 89.0 95.0 354.0 250.0</td>\n",
       "      <td>11784</td>\n",
       "      <td>89.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11784</th>\n",
       "      <td>11785 157.0 62.0 184.0 219.0</td>\n",
       "      <td>11785</td>\n",
       "      <td>157.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11785</th>\n",
       "      <td>11786 190.0 102.0 198.0 202.0</td>\n",
       "      <td>11786</td>\n",
       "      <td>190.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11786</th>\n",
       "      <td>11787 3.0 20.0 408.0 307.0</td>\n",
       "      <td>11787</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11787</th>\n",
       "      <td>11788 20.0 113.0 177.0 263.0</td>\n",
       "      <td>11788</td>\n",
       "      <td>20.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11788 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                bbox  index     x1     y1     x2     y2\n",
       "0            1 60.0 27.0 325.0 304.0      1   60.0   27.0  325.0  304.0\n",
       "1           2 139.0 30.0 153.0 264.0      2  139.0   30.0  153.0  264.0\n",
       "2           3 14.0 112.0 388.0 186.0      3   14.0  112.0  388.0  186.0\n",
       "3           4 112.0 90.0 255.0 242.0      4  112.0   90.0  255.0  242.0\n",
       "4            5 70.0 50.0 134.0 303.0      5   70.0   50.0  134.0  303.0\n",
       "...                              ...    ...    ...    ...    ...    ...\n",
       "11783    11784 89.0 95.0 354.0 250.0  11784   89.0   95.0  354.0  250.0\n",
       "11784   11785 157.0 62.0 184.0 219.0  11785  157.0   62.0  184.0  219.0\n",
       "11785  11786 190.0 102.0 198.0 202.0  11786  190.0  102.0  198.0  202.0\n",
       "11786     11787 3.0 20.0 408.0 307.0  11787    3.0   20.0  408.0  307.0\n",
       "11787   11788 20.0 113.0 177.0 263.0  11788   20.0  113.0  177.0  263.0\n",
       "\n",
       "[11788 rows x 6 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to ground truth bounding boxes \n",
    "ground_truth_bb = pd.read_csv('/Users/lucialarraona/Desktop/responsibleai/ConceptBottleneck/CUB/CUB_200_2011/CUB_200_2011/bounding_boxes.txt', header=None)\n",
    "df= ground_truth_bb.rename(columns = { 0 : 'bbox'})\n",
    "\n",
    "# split bbox column into separate columns\n",
    "df[[\"index\", \"x1\", \"y1\", \"x2\", \"y2\"]] = df[\"bbox\"].str.split(\" \", expand=True)\n",
    "\n",
    "# convert values to appropriate data types\n",
    "df[\"index\"] = df[\"index\"].astype(int)\n",
    "df[\"x1\"] = df[\"x1\"].astype(float)\n",
    "df[\"y1\"] = df[\"y1\"].astype(float)\n",
    "df[\"x2\"] = df[\"x2\"].astype(float)\n",
    "df[\"y2\"] = df[\"y2\"].astype(float)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_iou(PATH_saliency_map, df):\n",
    "    \n",
    "    # Load the saliency map and ground truth bounding box\n",
    "    saliency_map = cv2.imread(PATH_saliency_map, cv2.IMREAD_GRAYSCALE)\n",
    "    x1, y1, x2, y2 = df['x1'],df['x2'],df['x3'],df['x4']  # example bounding box coordinates\n",
    "\n",
    "    # Calculate the intersection and union areas\n",
    "    intersection = np.sum(saliency_map[y1:y2, x1:x2] > 0)\n",
    "    union = np.sum(saliency_map > 0) + (x2-x1)*(y2-y1) - intersection\n",
    "\n",
    "    # Calculate the IoU\n",
    "    iou = intersection / union\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concepts vs attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensibility of explanations provided by each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could be assessed through a user study where participants are presented with explanations generated by each model and are asked to rate them based on how understandable they are. We can also use metrics such as reading time or error rates to evaluate the effectiveness of the explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the sucess of the two models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the success of the two models, we can conduct a randomized controlled trial where participants are randomly assigned to either the saliency map or concept bottleneck group. Each group would be presented with the same set of input-output pairs and the explanations generated by their respective models. We can then collect data on accuracy and comprehensibility and compare the results between the two groups using statistical tests such as t-tests or ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
